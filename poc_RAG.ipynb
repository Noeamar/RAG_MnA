{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader, TextLoader, UnstructuredFileLoader\n",
    "import pandas as pd\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import json\n",
    "from langchain.load import dumps, loads\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remodel du fichier CSV Scraped Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier CSV a été réorganisé et enregistré sous : C:\\Users\\namar\\Documents\\poc_RAG\\Projet_test\\RAG_M-A\\Data\\scraped_companies_reorganized.csv\n"
     ]
    }
   ],
   "source": [
    "# Chemin du fichier d'entrée\n",
    "input_file_path = \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_M-A\\\\Data\\\\scraped_companies_all_columns.csv\"\n",
    "\n",
    "# Chemin du fichier de sortie\n",
    "output_file_path = \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_M-A\\\\Data\\\\scraped_companies_reorganized.csv\"\n",
    "\n",
    "# Charger le fichier CSV\n",
    "df = pd.read_csv(input_file_path)\n",
    "\n",
    "# Renommer les colonnes\n",
    "df.columns = [\n",
    "    \"Logo\", \"Column_to_remove\", \"Société\", \"Pays Siege\",\n",
    "    \"Siège répertorié sur Arx\", \"Site internet\", \"Secteur\",\n",
    "    \"Mots-clés\", \"Description\", \"Dernier CA (M)\", \"Périmètre CA\",\n",
    "    \"Column_to_remove_2\", \"TCAM (%)\", \"Dirigeants/Equipe CF\", \"Cotation\", \"ISIN\"\n",
    "]\n",
    "\n",
    "\n",
    "# Sélectionner et réorganiser les colonnes selon la spécification\n",
    "columns_to_keep = [\n",
    "    \"Société\",\n",
    "    \"Pays Siege\",\n",
    "    \"Siège répertorié sur Arx\",\n",
    "    \"Site internet\",\n",
    "    \"Secteur\",\n",
    "    \"Mots-clés\",\n",
    "    \"Description\",\n",
    "    \"Dernier CA (M)\",\n",
    "    \"Périmètre CA\",\n",
    "    \"TCAM (%)\",\n",
    "    \"Dirigeants/Equipe CF\",\n",
    "    \"Cotation\",\n",
    "    \"ISIN\"\n",
    "]\n",
    "\n",
    "# Renommer les colonnes sélectionnées pour plus de clarté (facultatif)\n",
    "renamed_columns = [\n",
    "    \"Company\", \"Country Headquarters\", \"Arx Listed HQ\", \"Website\",\n",
    "    \"Sector\", \"Keywords\", \"Description\", \"Latest Revenue (M)\",\n",
    "    \"Revenue Scope\", \"CAGR (%)\", \"Executives/Team CF\", \"Rating\", \"ISIN\"\n",
    "]\n",
    "\n",
    "# Réorganiser et renommer les colonnes\n",
    "df_reorganized = df[columns_to_keep]\n",
    "df_reorganized.columns = renamed_columns\n",
    "\n",
    "# Enregistrer le fichier CSV modifié\n",
    "df_reorganized.to_csv(output_file_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Le fichier CSV a été réorganisé et enregistré sous : {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des fichiers dans docs pour préparer l'embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de documents : 3\n",
      "Document : scraped_companies_reorganized.csv, Métadonnées : {'file_name': 'scraped_companies_reorganized.csv'}\n",
      "Document : scraped_news_grid.csv, Métadonnées : {'file_name': 'scraped_news_grid.csv'}\n",
      "Document : exported_results.csv, Métadonnées : {'file_name': 'exported_results.csv'}\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour charger un fichier et extraire les données avec métadonnées\n",
    "def load_files_with_metadata(file_paths, metadata_file):\n",
    "    # Charger les métadonnées\n",
    "    with open(metadata_file, 'r') as meta_file:\n",
    "        metadata = json.load(meta_file)\n",
    "    \n",
    "    docs = []\n",
    "    for path in file_paths:\n",
    "        file_name = path.split(\"\\\\\")[-1]  # Extraire le nom du fichier\n",
    "        file_metadata = metadata.get(file_name, {})  # Récupérer les métadonnées\n",
    "\n",
    "        # Initialiser le contenu du document\n",
    "        content = \"\"\n",
    "        if path.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(path)\n",
    "            content = \"\\n\".join([doc.page_content for doc in loader.load()])\n",
    "        elif path.endswith(\".txt\"):\n",
    "            loader = TextLoader(path)\n",
    "            content = \"\\n\".join([doc.page_content for doc in loader.load()])\n",
    "        elif path.endswith(\".csv\"):\n",
    "            df = pd.read_csv(path)\n",
    "            if 'Title' in df.columns and 'Content' in df.columns:\n",
    "                df['text'] = df['Title'] + \"\\n\\n\" + df['Content']\n",
    "            else:\n",
    "                df['text'] = df.apply(lambda row: ' '.join(map(str, row.values)), axis=1)\n",
    "            content = \"\\n\".join(df['text'].tolist())\n",
    "        \n",
    "        # Créer un document global pour le fichier avec les métadonnées\n",
    "        doc = Document(\n",
    "            page_content=content,\n",
    "            metadata={\n",
    "                \"file_name\": file_name,\n",
    "                **file_metadata  # Ajouter les métadonnées depuis le JSON\n",
    "            }\n",
    "        )\n",
    "        docs.append(doc)\n",
    "    \n",
    "    return docs\n",
    "\n",
    "# Exemple d'utilisation\n",
    "file_paths = [\n",
    "    \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_M-A\\\\Data\\\\scraped_companies_reorganized.csv\",\n",
    "    \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_M-A\\\\Data\\\\scraped_news_grid.csv\",\n",
    "    \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_M-A\\\\Data\\\\exported_results.csv\"\n",
    "]\n",
    "\n",
    "metadata_file = \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_M-A\\\\metadata_arx.json\"\n",
    "\n",
    "# Charger les fichiers avec métadonnées\n",
    "docs = load_files_with_metadata(file_paths, metadata_file)\n",
    "\n",
    "# Résumé des documents chargés\n",
    "print(f\"Nombre total de documents : {len(docs)}\")\n",
    "for doc in docs:\n",
    "    print(f\"Document : {doc.metadata['file_name']}, Métadonnées : {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding (Attention a ne pas le lancer a chaque fois !!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings générés et stockés dans ChromaDB.\n"
     ]
    }
   ],
   "source": [
    "# Diviser chaque document en morceaux plus petits\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Générer et persister les embeddings\n",
    "persist_directory = \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_M-A\\\\Data\\\\ChromaDB\"\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "vectorstore.persist()\n",
    "print(\"Embeddings générés et stockés dans ChromaDB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorStore chargé depuis le disque.\n",
      "\n",
      "Résultats de la requête :\n",
      "Imagerie Cardinet France Paris www.imagerie-cardinet.fr Santé Intégration de logiciel (radiologie), Imagerie médicale, Image numérique, Imagerie dentaire, Traitement numérique d'images, Radiologie, Analyse médicale, Traitement d'image numérique Imagerie Cardinet est une entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients. n.a. n.a. n.a. n.a. n.a. n.a.\n",
      "Imagerie Cardinet France Paris www.imagerie-cardinet.fr Santé Intégration de logiciel (radiologie), Imagerie médicale, Image numérique, Imagerie dentaire, Traitement numérique d'images, Radiologie, Analyse médicale, Traitement d'image numérique Imagerie Cardinet est une entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients. n.a. n.a. n.a. n.a. n.a. n.a.\n",
      "Imagerie Cardinet France Paris www.imagerie-cardinet.fr Santé Intégration de logiciel (radiologie), Imagerie médicale, Image numérique, Imagerie dentaire, Traitement numérique d'images, Radiologie, Analyse médicale, Traitement d'image numérique Imagerie Cardinet est une entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients. n.a. n.a. n.a. n.a. n.a. n.a.\n",
      "Imagerie Cardinet France Paris www.imagerie-cardinet.fr Santé Intégration de logiciel (radiologie), Imagerie médicale, Image numérique, Imagerie dentaire, Traitement numérique d'images, Radiologie, Analyse médicale, Traitement d'image numérique Imagerie Cardinet est une entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients. n.a. n.a. n.a. n.a. n.a. n.a.\n",
      "Imagerie Cardinet France Paris www.imagerie-cardinet.fr Santé Intégration de logiciel (radiologie), Imagerie médicale, Image numérique, Imagerie dentaire, Traitement numérique d'images, Radiologie, Analyse médicale, Traitement d'image numérique Imagerie Cardinet est une entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients. n.a. n.a. n.a. n.a. n.a. n.a.\n",
      "Imagerie Cardinet France Paris www.imagerie-cardinet.fr Santé Intégration de logiciel (radiologie), Imagerie médicale, Image numérique, Imagerie dentaire, Traitement numérique d'images, Radiologie, Analyse médicale, Traitement d'image numérique Imagerie Cardinet est une entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients. n.a. n.a. n.a. n.a. n.a. n.a.\n",
      "Build-up : Imagerie Cardinet se rapproche du groupe de centres de radiologie générale Radiologie Paris Ouest Soutenue par Andera Acto depuis 2023, Imagerie Cardinet (Île-de-France / FRA), entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients, se rapproche de Radiologie Paris Ouest (Île-de-France / FRA), groupe de centres de radiologie générale et spécialisée. Cette collaboration vise à renforcer leur modèle entrepreneurial en\n",
      "Cession : Imagerie Cardinet se rapproche du groupe de centres de radiologie générale Radiologie Paris Ouest Soutenue par Andera Acto depuis 2023, Imagerie Cardinet (Île-de-France / FRA), entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients, se rapproche de Radiologie Paris Ouest (Île-de-France / FRA), groupe de centres de radiologie générale et spécialisée. Cette collaboration vise à renforcer leur modèle entrepreneurial en\n",
      "Build-up : Imagerie Cardinet se rapproche du groupe de centres de radiologie générale Radiologie Paris Ouest Soutenue par Andera Acto depuis 2023, Imagerie Cardinet (Île-de-France / FRA), entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients, se rapproche de Radiologie Paris Ouest (Île-de-France / FRA), groupe de centres de radiologie générale et spécialisée. Cette collaboration vise à renforcer leur modèle entrepreneurial en imagerie médicale et à accélérer le développement de leurs activités dans la région parisienne. Dans le cadre de la transaction, Azulis Capital a cédé sa participation minoritaire détenue depuis 2019 dans\n",
      "Cession : Imagerie Cardinet se rapproche du groupe de centres de radiologie générale Radiologie Paris Ouest Soutenue par Andera Acto depuis 2023, Imagerie Cardinet (Île-de-France / FRA), entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients, se rapproche de Radiologie Paris Ouest (Île-de-France / FRA), groupe de centres de radiologie générale et spécialisée. Cette collaboration vise à renforcer leur modèle entrepreneurial en imagerie médicale et à accélérer le développement de leurs activités dans la région parisienne. Dans le cadre de la transaction, Azulis Capital a cédé sa participation minoritaire détenue depuis 2019 dans Radiologie Paris Ouest (Andera Partners, communiqué de presse) 29/11/2024\n"
     ]
    }
   ],
   "source": [
    "# Recharger le vectorstore depuis le répertoire persist_directory\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=\"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_M-A\\\\Data\\\\ChromaDB\",\n",
    "    embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "print(\"VectorStore chargé depuis le disque.\")\n",
    "\n",
    "\n",
    "# Créer un système de récupération\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",  # Utiliser Maximal Marginal Relevance\n",
    "    search_kwargs={\n",
    "        \"k\": 10,  # Récupérer plus de documents\n",
    "        \"score_threshold\": 0.01  # Réduire le seuil de score pour inclure plus de résultats\n",
    "    }\n",
    ")\n",
    "\n",
    "# Exemple de requête\n",
    "query = \"Imagerie cardinet\"\n",
    "results = retriever.get_relevant_documents(query)\n",
    "\n",
    "print(\"\\nRésultats de la requête :\")\n",
    "for result in results:\n",
    "    print(result.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération avec LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG MULTI QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Vulcain Engineering connaît plusieurs nouveautés significatives récemment, renforçant sa position sur le marché de l'ingénierie dans le secteur de l'énergie et au-delà :\\n\\n1. **Réorganisation du Capital via un LBO** :\\n   - **Opération de LBO** : En 2022, Vulcain Engineering a procédé à une réorganisation de son capital à l'occasion d'un leveraged buy-out (LBO).\\n   - **Nouveau Consortium d'Investisseurs** : L'opération a accueilli un consortium composé de **Ardian**, **Tikehau Capital**, **EMZ**, **Bpifrance**, **Amundi** et du **Fonds France Nucléaire** (géré par Siparex).\\n   - **Soutien Financier** : Cette réorganisation a été soutenue par une dette senior provenant d'un pool bancaire et par un financement mezzanine de **Eurazeo Private Debt**.\\n   - **Cession des Participations** : Les actionnaires existants, **Equistone Partners Europe** et **Sagard**, ont cédé leurs participations dans ce cadre.\\n\\n2. **Stratégie de Build-up et Acquisitions** :\\n   - **Acquisition d'Evolutec Ingénierie** : En 2019, Vulcain Engineering a racheté Evolutec Ingénierie, renforçant ainsi son expertise dans les domaines de l'énergie et de la chimie.\\n   - **Acquisition d'Apsalys** : Plus récemment, Vulcain a acquis **Apsalys**, un éditeur de logiciels de gestion de la qualité basés sur le cloud pour le secteur des sciences de la vie. Cette acquisition permet à Vulcain de diversifier son offre et de prioriser son développement dans ce secteur en pleine croissance.\\n   - **Acquisition de Pagoline Groupe** : Vulcain Engineering a également acquis **Pagoline Groupe**, spécialisé dans l'ingénierie appliquée aux réseaux et infrastructures, notamment dans l'énergie, le transport ferroviaire et les télécommunications. Cette acquisition est un élément clé pour la croissance à long terme de l'entreprise.\\n\\n3. **Expansion et Renforcement de l'Offre de Services** :\\n   - **Expansion Internationale** : La nouvelle structure capitalistique vise à soutenir l'expansion internationale de Vulcain Engineering, lui permettant de renforcer sa présence sur de nouveaux marchés.\\n   - **Diversification des Services** : En intégrant des entreprises comme Apsalys et Pagoline, Vulcain renforce son offre de services, couvrant désormais davantage de secteurs tels que les sciences de la vie, les infrastructures de transport et les télécommunications.\\n\\n4. **Soutien de Partenaires Stratégiques** :\\n   - **Présence dans les Portefeuilles d'Investisseurs** : Vulcain est également présente dans les portefeuilles de **Nixen Partners**, **Trocadero Capital Partners** et **Initiative & Finance**, ce qui témoigne de la confiance continue des investisseurs dans la stratégie de croissance de l'entreprise.\\n\\nCes développements témoignent de la dynamique de croissance de Vulcain Engineering, qui s'appuie sur des opérations de financement structurées et une stratégie d'acquisitions ciblées pour renforcer sa position sur le marché et diversifier ses domaines d'expertise.\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi Query: Different Perspectives\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate ten \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspectives \n",
    "    | ChatOpenAI(model= 'o1-mini') \n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    " \n",
    "# Retrieve\n",
    "question = \"Quelles nouveautées pour Vulcain ingénierie ?\"\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\":question})\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Tu es un assistant chatbot qui travaille dans un cabinet de finance d'entreprise. Ton rôle est de donner les informations les plus pertinentes possibles en te basant sur les sources que tu as. Voici le contexte pour t'aider:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOpenAI(model='o1-mini')\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG FUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Les dernières actualités concernant **Imagerie Cardinet** indiquent une collaboration significative avec le groupe **Radiologie Paris Ouest**. Voici les points clés de cette évolution :\\n\\n1. **Rapprochement avec Radiologie Paris Ouest** :\\n   - **Imagerie Cardinet**, spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients, a récemment renforcé ses liens avec **Radiologie Paris Ouest**, un groupe de centres de radiologie générale et spécialisée basé en Île-de-France.\\n   \\n2. **Soutien d'Andera Acto** :\\n   - Cette collaboration est soutenue par **Andera Acto** depuis 2023, ce qui apporte un appui financier et stratégique à l'initiative.\\n\\n3. **Objectifs de la Collaboration** :\\n   - **Renforcement du modèle entrepreneurial** en imagerie médicale.\\n   - **Accélération du développement** des activités dans la région parisienne, visant à offrir des services d'imagerie médicale plus étendus et de meilleure qualité.\\n\\n4. **Transaction Financière** :\\n   - Dans le cadre de cette collaboration, **Azulis Capital** a cédé sa participation minoritaire détenue depuis 2019 dans **Radiologie Paris Ouest**. Cette cession fait partie du réajustement stratégique visant à consolider les opérations et à optimiser les ressources au sein des groupes concernés.\\n\\nCette initiative reflète l'engagement d'Imagerie Cardinet à renforcer sa position sur le marché de l'imagerie médicale en France, en s'associant avec des acteurs clés du secteur pour offrir des services améliorés et étendus aux patients et professionnels de santé.\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAG-Fusion: Related\n",
    "template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (4 queries):\"\"\"\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_rag_fusion \n",
    "    | ChatOpenAI(model='o1-mini')\n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\" Reciprocal_rank_fusion that takes multiple lists of ranked documents \n",
    "        and an optional parameter k used in the RRF formula \"\"\"\n",
    "    \n",
    "    # Initialize a dictionary to hold fused scores for each unique document\n",
    "    fused_scores = {}\n",
    "\n",
    "    # Iterate through each list of ranked documents\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)\n",
    "            doc_str = dumps(doc)\n",
    "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # Retrieve the current score of the document, if any\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # Update the score of the document using the RRF formula: 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
    "    return reranked_results\n",
    "\n",
    "retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "docs = retrieval_chain_rag_fusion.invoke({\"question\": question})\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain_rag_fusion, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
