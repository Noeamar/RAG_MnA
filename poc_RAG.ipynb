{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader, TextLoader, UnstructuredFileLoader\n",
    "import pandas as pd\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import json\n",
    "from langchain.load import dumps, loads\n",
    "from operator import itemgetter\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remodel du fichier CSV Scraped Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier CSV a été réorganisé et enregistré sous : C:\\Users\\namar\\Documents\\poc_RAG\\Projet_test\\RAG_M-A\\Data\\scraped_companies_reorganized.csv\n"
     ]
    }
   ],
   "source": [
    "# # Chemin du fichier d'entrée\n",
    "# input_file_path = \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_M-A\\\\Data\\\\scraped_companies_all_columns.csv\"\n",
    "\n",
    "# # Chemin du fichier de sortie\n",
    "# output_file_path = \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_M-A\\\\Data\\\\scraped_companies_reorganized.csv\"\n",
    "\n",
    "# # Charger le fichier CSV\n",
    "# df = pd.read_csv(input_file_path)\n",
    "\n",
    "# # Renommer les colonnes\n",
    "# df.columns = [\n",
    "#     \"Logo\", \"Column_to_remove\", \"Société\", \"Pays Siege\",\n",
    "#     \"Siège répertorié sur Arx\", \"Site internet\", \"Secteur\",\n",
    "#     \"Mots-clés\", \"Description\", \"Dernier CA (M)\", \"Périmètre CA\",\n",
    "#     \"Column_to_remove_2\", \"TCAM (%)\", \"Dirigeants/Equipe CF\", \"Cotation\", \"ISIN\"\n",
    "# ]\n",
    "\n",
    "\n",
    "# # Sélectionner et réorganiser les colonnes selon la spécification\n",
    "# columns_to_keep = [\n",
    "#     \"Société\",\n",
    "#     \"Pays Siege\",\n",
    "#     \"Siège répertorié sur Arx\",\n",
    "#     \"Site internet\",\n",
    "#     \"Secteur\",\n",
    "#     \"Mots-clés\",\n",
    "#     \"Description\",\n",
    "#     \"Dernier CA (M)\",\n",
    "#     \"Périmètre CA\",\n",
    "#     \"TCAM (%)\",\n",
    "#     \"Dirigeants/Equipe CF\",\n",
    "#     \"Cotation\",\n",
    "#     \"ISIN\"\n",
    "# ]\n",
    "\n",
    "# # Renommer les colonnes sélectionnées pour plus de clarté (facultatif)\n",
    "# renamed_columns = [\n",
    "#     \"Company\", \"Country Headquarters\", \"Arx Listed HQ\", \"Website\",\n",
    "#     \"Sector\", \"Keywords\", \"Description\", \"Latest Revenue (M)\",\n",
    "#     \"Revenue Scope\", \"CAGR (%)\", \"Executives/Team CF\", \"Rating\", \"ISIN\"\n",
    "# ]\n",
    "\n",
    "# # Réorganiser et renommer les colonnes\n",
    "# df_reorganized = df[columns_to_keep]\n",
    "# df_reorganized.columns = renamed_columns\n",
    "\n",
    "# # Enregistrer le fichier CSV modifié\n",
    "# df_reorganized.to_csv(output_file_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# print(f\"Le fichier CSV a été réorganisé et enregistré sous : {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des données importées après suppression de la première colonne :\n",
      "   Position          Fonds                                          Véhicules  \\\n",
      "0         1      21 invest  21 Invest Continuation Fund (2024)\\n21 Invest ...   \n",
      "1         2  Goldman Sachs                                                NaN   \n",
      "2         3       3i Group  3i 2020 Co-investment Programme (2020): Single...   \n",
      "3         4          HSBC                                                 NaN   \n",
      "4         5         Abénex  Abenex Continuation Fund (2024)\\nAbenex Small-...   \n",
      "\n",
      "         Catégorie Géographie d'investissement   HQ                  Bureaux  \\\n",
      "0  Fonds classique                      Europe  NaN  France\\nItalie\\nPologne   \n",
      "1          Banque                International  NaN                      NaN   \n",
      "2  Fonds classique                  Europe\\nUS  NaN        Europe \\nUS\\nAsia   \n",
      "3          Banque                          NaN  NaN                      NaN   \n",
      "4  Fonds classique                      France  NaN              Paris, Lyon   \n",
      "\n",
      "  Ticket \\n(m€) Ticket Min \\n(m€) Ticket Max\\n(m€)     Type d'investissement  \\\n",
      "0       20 - 60               20                60  Majoritaire/Minoritaire    \n",
      "1           NaN               NaN              NaN                       NaN   \n",
      "2      25 - 300               25               300  Majoritaire/Minoritaire    \n",
      "3           NaN               NaN              NaN            Prêt bancaire    \n",
      "4      10 - 100               10               100  Majoritaire/Minoritaire    \n",
      "\n",
      "                                        Contact Contact qualifié (Oui/Non)  \\\n",
      "0          Stephane Periquet (Managing Partner)                        Non   \n",
      "1                                           NaN                        NaN   \n",
      "2  Remi Carnimolla (Parner, Managing Director)                         Non   \n",
      "3                                           NaN                        NaN   \n",
      "4               Olivier Moatti (Associé Gérant)                        Oui   \n",
      "\n",
      "      Secteurs                             Appétence pour secteur  \\\n",
      "0  Généraliste                                               n.a.   \n",
      "1          NaN                                                NaN   \n",
      "2  Spécialiste  Business & Tachnology Services\\nConsumer\\nHeal...   \n",
      "3          NaN                                                NaN   \n",
      "4  Spécialiste  Grande consommation, Services B&B, Industrie, ...   \n",
      "\n",
      "    Thèse d'investissement (VE/EBITDA cible) Approché dans Opérations D&A   \\\n",
      "0  VE: 30 - 150 m€\\nEntreprise en croissance                           NaN   \n",
      "1                                        NaN                           NaN   \n",
      "2                           VE : 50 - 500 m€                       Novomed   \n",
      "3                                        NaN                           NaN   \n",
      "4                           VE : 100 - 300m€                    Cruiseline   \n",
      "\n",
      "                         Sources Plaquette  Commentaires  \n",
      "0             Arx, Site internet        Non          NaN  \n",
      "1                            NaN        NaN          NaN  \n",
      "2  Arx, Site internet, Plaquette        Oui          NaN  \n",
      "3                            NaN        NaN          NaN  \n",
      "4             Arx, Site internet        Non          NaN  \n",
      "Fichier CSV sauvegardé à : C:\\Users\\namar\\Documents\\poc_RAG\\Projet_test\\RAG_MnA\\Data\\fichier_fonds_suppl.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\namar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Chemin vers votre fichier Excel\n",
    "excel_file = \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_MnA\\\\Data\\\\20240924_Base_fonds PE & Dette.xlsx\"\n",
    "\n",
    "# Lire le fichier Excel en spécifiant que la troisième ligne (index 2) contient les noms des colonnes\n",
    "# Remplacez 'sheet_name=1' par le nom de la feuille si nécessaire\n",
    "df_excel = pd.read_excel(excel_file, sheet_name=1, header=2)\n",
    "\n",
    "# Supprimer la première colonne\n",
    "df_excel = df_excel.iloc[:, 1:]\n",
    "\n",
    "# Vérifiez les premières lignes pour vous assurer que la première colonne a bien été supprimée\n",
    "print(\"Aperçu des données importées après suppression de la première colonne :\")\n",
    "print(df_excel.head())\n",
    "\n",
    "# Chemin où sauvegarder le CSV\n",
    "csv_file_new_fonds = \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_MnA\\\\Data\\\\fichier_fonds_suppl.csv\"\n",
    "\n",
    "# Sauvegarder en CSV avec les noms de colonnes corrects\n",
    "df_excel.to_csv(csv_file_new_fonds, index=False, encoding='utf-8')\n",
    "print(f\"Fichier CSV sauvegardé à : {csv_file_new_fonds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes dans pe_firms_cleaned.csv : ['Fonds', 'Pays / Info', 'Secteurs']\n",
      "Colonnes dans fichier_fonds_suppl.csv : ['Position', 'Fonds', 'Véhicules', 'Catégorie', \"Géographie d'investissement\", 'HQ', 'Bureaux', 'Ticket \\n(m€)', 'Ticket Min \\n(m€)', 'Ticket Max\\n(m€)', \"Type d'investissement\", 'Contact', 'Contact qualifié (Oui/Non)', 'Secteurs', 'Appétence pour secteur', \"Thèse d'investissement (VE/EBITDA cible)\", 'Approché dans Opérations D&A ', 'Sources', 'Plaquette ', 'Commentaires']\n",
      "Fichier combiné sauvegardé à : C:\\Users\\namar\\Documents\\poc_RAG\\Projet_test\\RAG_MnA\\Data\\pe_firms_combined.csv\n"
     ]
    }
   ],
   "source": [
    "# Chemins vers les fichiers CSV\n",
    "old_csv = \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_MnA\\\\Data\\\\pe_firms_cleaned.csv\"\n",
    "new_csv = \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_MnA\\\\Data\\\\fichier_fonds_suppl.csv\"\n",
    "combined_csv = \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_MnA\\\\Data\\\\pe_firms_combined.csv\"\n",
    "\n",
    "# Lire les fichiers CSV\n",
    "df_old = pd.read_csv(old_csv)\n",
    "df_new = pd.read_csv(new_csv)\n",
    "\n",
    "# Vérifiez les colonnes de df_new et harmonisez-les avec df_old\n",
    "print(\"Colonnes dans pe_firms_cleaned.csv :\", df_old.columns.tolist())\n",
    "print(\"Colonnes dans fichier_fonds_suppl.csv :\", df_new.columns.tolist())\n",
    "\n",
    "# Ajouter les nouvelles colonnes manquantes dans df_old avec des valeurs manquantes\n",
    "for col in df_new.columns:\n",
    "    if col not in df_old.columns:\n",
    "        df_old[col] = pd.NA\n",
    "\n",
    "# Concaténer les DataFrames\n",
    "df_combined = pd.concat([df_old, df_new], ignore_index=True)\n",
    "\n",
    "# Sauvegarder le fichier combiné\n",
    "df_combined.to_csv(combined_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Fichier combiné sauvegardé à : {combined_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des fichiers dans docs pour préparer l'embedding + Embedding (Attention a ne pas le lancer a chaque fois !!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de documents chargés : 6\n",
      "Nombre de chunks après splitting : 63178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\namar\\AppData\\Local\\Temp\\ipykernel_21156\\1645182019.py:62: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings()\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: os.geten***************EY\"). You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 83\u001b[0m\n\u001b[0;32m     80\u001b[0m metadata_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mnamar\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mpoc_RAG\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mProjet_test\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mRAG_MnA\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmetadata_arx.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m faiss_index_path_all \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mnamar\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mpoc_RAG\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mProjet_test\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mRAG_MnA\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mData\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mFAISS_index_multiples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 83\u001b[0m \u001b[43mgenerate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfaiss_index_path_all\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Vous pouvez ensuite appeler la même fonction pour la base \"actualités\" uniquement,\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# ou la base \"fonds\" uniquement, en modifiant la liste de fichiers et le chemin de l'index FAISS.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Et ainsi de suite pour les actualités.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 63\u001b[0m, in \u001b[0;36mgenerate_embeddings\u001b[1;34m(file_paths, metadata_file, faiss_index_path)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Créer les embeddings et le vectorstore FAISS\u001b[39;00m\n\u001b[0;32m     62\u001b[0m embedding \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings()\n\u001b[1;32m---> 63\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Sauvegarder l'index FAISS dans un dossier local\u001b[39;00m\n\u001b[0;32m     66\u001b[0m vectorstore\u001b[38;5;241m.\u001b[39msave_local(faiss_index_path)\n",
      "File \u001b[1;32mc:\\Users\\namar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:852\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[1;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[0;32m    850\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ids\n\u001b[1;32m--> 852\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\namar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1041\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1022\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[0;32m   1024\u001b[0m \n\u001b[0;32m   1025\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1041\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[0;32m   1043\u001b[0m         texts,\n\u001b[0;32m   1044\u001b[0m         embeddings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1049\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\namar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:671\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    670\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\namar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:497\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    495\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[1;32m--> 497\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43membed_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invocation_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    503\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mdict()\n",
      "File \u001b[1;32mc:\\Users\\namar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:120\u001b[0m, in \u001b[0;36membed_with_retry\u001b[1;34m(embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the embedding call.\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(embeddings)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_embed_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[1;32mc:\\Users\\namar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\resources\\embeddings.py:124\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    118\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    119\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\namar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1279\u001b[0m     )\n\u001b[1;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\namar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\namar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1070\u001b[0m )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: os.geten***************EY\"). You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "def load_files_with_metadata(file_paths, metadata_file):\n",
    "    # Charger les métadonnées\n",
    "    with open(metadata_file, 'r', encoding=\"utf-8\") as meta_file:\n",
    "        metadata = json.load(meta_file)\n",
    "    \n",
    "    docs = []\n",
    "    for path in file_paths:\n",
    "        file_name = os.path.basename(path)  # Extraire le nom du fichier\n",
    "        file_metadata = metadata.get(file_name, {})  # Récupérer les métadonnées\n",
    "\n",
    "        # Initialiser le contenu du document\n",
    "        content = \"\"\n",
    "        if path.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(path)\n",
    "            content = \"\\n\".join([doc.page_content for doc in loader.load()])\n",
    "        elif path.endswith(\".txt\"):\n",
    "            loader = TextLoader(path)\n",
    "            content = \"\\n\".join([doc.page_content for doc in loader.load()])\n",
    "        elif path.endswith(\".csv\"):\n",
    "            df = pd.read_csv(path)\n",
    "            # Adapter selon la structure de vos CSV\n",
    "            if 'Title' in df.columns and 'Content' in df.columns:\n",
    "                df['text'] = df['Title'] + \"\\n\\n\" + df['Content']\n",
    "            else:\n",
    "                df['text'] = df.apply(lambda row: ' '.join(map(str, row.values)), axis=1)\n",
    "            content = \"\\n\".join(df['text'].tolist())\n",
    "        else:\n",
    "            # Si d'autres formats sont prévus, les gérer ici\n",
    "            pass\n",
    "        \n",
    "        doc = Document(\n",
    "            page_content=content,\n",
    "            metadata={\n",
    "                \"file_name\": file_name,\n",
    "                **file_metadata  # Ajouter les métadonnées depuis le JSON\n",
    "            }\n",
    "        )\n",
    "        docs.append(doc)\n",
    "    \n",
    "    return docs\n",
    "\n",
    "def generate_embeddings(file_paths, metadata_file, faiss_index_path):\n",
    "    # Charger les documents avec métadonnées\n",
    "    docs = load_files_with_metadata(file_paths, metadata_file)\n",
    "    print(f\"Nombre total de documents chargés : {len(docs)}\")\n",
    "\n",
    "    # Diviser chaque document en morceaux plus petits\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    print(f\"Nombre de chunks après splitting : {len(splits)}\")\n",
    "\n",
    "    # Créer les embeddings et le vectorstore FAISS\n",
    "    embedding = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(splits, embedding)\n",
    "\n",
    "    # Sauvegarder l'index FAISS dans un dossier local\n",
    "    vectorstore.save_local(faiss_index_path)\n",
    "    print(f\"Embeddings générés et stockés dans : {faiss_index_path}\")\n",
    "\n",
    "# Exemple d'utilisation pour une base de données complète :\n",
    "all_files = [\n",
    "    \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_MnA\\\\Data\\\\pe_firms_combined_Arx.csv\",\n",
    "    \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_MnA\\\\Data\\\\scraped_companies_reorganized_Arx.csv\",\n",
    "    \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_MnA\\\\Data\\\\scraped_news_grid_Arx.csv\",\n",
    "    \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_MnA\\\\Data\\\\exported_results.csv\",\n",
    "    \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_MnA\\\\Data\\\\deals_data_cleaned_CFNews.csv\",\n",
    "    \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_MnA\\\\Data\\\\deals_MergerMarket.csv\"\n",
    "\n",
    "]\n",
    "\n",
    "metadata_file = \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_MnA\\\\metadata_arx.json\"\n",
    "faiss_index_path_all = \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_MnA\\\\Data\\\\FAISS_index_multiples\"\n",
    "\n",
    "generate_embeddings(all_files, metadata_file, faiss_index_path_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\namar\\AppData\\Local\\Temp\\ipykernel_30948\\622917514.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorStore chargé depuis le disque.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\namar\\AppData\\Local\\Temp\\ipykernel_30948\\622917514.py:21: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Résultats de la requête :\n",
      "Imagerie Cardinet France Paris www.imagerie-cardinet.fr Santé Intégration de logiciel (radiologie), Imagerie médicale, Image numérique, Imagerie dentaire, Traitement numérique d'images, Radiologie, Analyse médicale, Traitement d'image numérique Imagerie Cardinet est une entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients. n.a. n.a. n.a. n.a. n.a. n.a.\n",
      "Imagerie Cardinet France Paris www.imagerie-cardinet.fr Santé Intégration de logiciel (radiologie), Imagerie médicale, Image numérique, Imagerie dentaire, Traitement numérique d'images, Radiologie, Analyse médicale, Traitement d'image numérique Imagerie Cardinet est une entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients. n.a. n.a. n.a. n.a. n.a. n.a.\n",
      "Imagerie Cardinet France Paris www.imagerie-cardinet.fr Santé Intégration de logiciel (radiologie), Imagerie médicale, Image numérique, Imagerie dentaire, Traitement numérique d'images, Radiologie, Analyse médicale, Traitement d'image numérique Imagerie Cardinet est une entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients. n.a. n.a. n.a. n.a. n.a. n.a.\n",
      "Imagerie Cardinet France Paris www.imagerie-cardinet.fr Santé Intégration de logiciel (radiologie), Imagerie médicale, Image numérique, Imagerie dentaire, Traitement numérique d'images, Radiologie, Analyse médicale, Traitement d'image numérique Imagerie Cardinet est une entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients. n.a. n.a. n.a. n.a. n.a. n.a.\n",
      "Imagerie Cardinet France Paris www.imagerie-cardinet.fr Santé Intégration de logiciel (radiologie), Imagerie médicale, Image numérique, Imagerie dentaire, Traitement numérique d'images, Radiologie, Analyse médicale, Traitement d'image numérique Imagerie Cardinet est une entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients. n.a. n.a. n.a. n.a. n.a. n.a.\n",
      "Imagerie Cardinet France Paris www.imagerie-cardinet.fr Santé Intégration de logiciel (radiologie), Imagerie médicale, Image numérique, Imagerie dentaire, Traitement numérique d'images, Radiologie, Analyse médicale, Traitement d'image numérique Imagerie Cardinet est une entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients. n.a. n.a. n.a. n.a. n.a. n.a.\n",
      "Build-up : Imagerie Cardinet se rapproche du groupe de centres de radiologie générale Radiologie Paris Ouest Soutenue par Andera Acto depuis 2023, Imagerie Cardinet (Île-de-France / FRA), entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients, se rapproche de Radiologie Paris Ouest (Île-de-France / FRA), groupe de centres de radiologie générale et spécialisée. Cette collaboration vise à renforcer leur modèle entrepreneurial en\n",
      "Cession : Imagerie Cardinet se rapproche du groupe de centres de radiologie générale Radiologie Paris Ouest Soutenue par Andera Acto depuis 2023, Imagerie Cardinet (Île-de-France / FRA), entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients, se rapproche de Radiologie Paris Ouest (Île-de-France / FRA), groupe de centres de radiologie générale et spécialisée. Cette collaboration vise à renforcer leur modèle entrepreneurial en\n",
      "Build-up : Imagerie Cardinet se rapproche du groupe de centres de radiologie générale Radiologie Paris Ouest Soutenue par Andera Acto depuis 2023, Imagerie Cardinet (Île-de-France / FRA), entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients, se rapproche de Radiologie Paris Ouest (Île-de-France / FRA), groupe de centres de radiologie générale et spécialisée. Cette collaboration vise à renforcer leur modèle entrepreneurial en imagerie médicale et à accélérer le développement de leurs activités dans la région parisienne. Dans le cadre de la transaction, Azulis Capital a cédé sa participation minoritaire détenue depuis 2019 dans\n",
      "Cession : Imagerie Cardinet se rapproche du groupe de centres de radiologie générale Radiologie Paris Ouest Soutenue par Andera Acto depuis 2023, Imagerie Cardinet (Île-de-France / FRA), entreprise spécialisée dans les services d'imagerie médicale pour les prestataires de soins de santé et les patients, se rapproche de Radiologie Paris Ouest (Île-de-France / FRA), groupe de centres de radiologie générale et spécialisée. Cette collaboration vise à renforcer leur modèle entrepreneurial en imagerie médicale et à accélérer le développement de leurs activités dans la région parisienne. Dans le cadre de la transaction, Azulis Capital a cédé sa participation minoritaire détenue depuis 2019 dans Radiologie Paris Ouest (Andera Partners, communiqué de presse) 29/11/2024\n"
     ]
    }
   ],
   "source": [
    "# Recharger le vectorstore depuis le répertoire persist_directory\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=\"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_M-A\\\\Data\\\\ChromaDB\",\n",
    "    embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "print(\"VectorStore chargé depuis le disque.\")\n",
    "\n",
    "\n",
    "# Créer un système de récupération\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",  # Utiliser Maximal Marginal Relevance\n",
    "    search_kwargs={\n",
    "        \"k\": 10,  # Récupérer plus de documents\n",
    "        \"score_threshold\": 0.01  # Réduire le seuil de score pour inclure plus de résultats\n",
    "    }\n",
    ")\n",
    "\n",
    "# Exemple de requête\n",
    "query = \"Imagerie cardinet\"\n",
    "results = retriever.get_relevant_documents(query)\n",
    "\n",
    "print(\"\\nRésultats de la requête :\")\n",
    "for result in results:\n",
    "    print(result.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération avec LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG MULTI QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Vulcain Engineering connaît plusieurs nouveautés significatives récemment, renforçant sa position sur le marché de l'ingénierie dans le secteur de l'énergie et au-delà :\\n\\n1. **Réorganisation du Capital via un LBO** :\\n   - **Opération de LBO** : En 2022, Vulcain Engineering a procédé à une réorganisation de son capital à l'occasion d'un leveraged buy-out (LBO).\\n   - **Nouveau Consortium d'Investisseurs** : L'opération a accueilli un consortium composé de **Ardian**, **Tikehau Capital**, **EMZ**, **Bpifrance**, **Amundi** et du **Fonds France Nucléaire** (géré par Siparex).\\n   - **Soutien Financier** : Cette réorganisation a été soutenue par une dette senior provenant d'un pool bancaire et par un financement mezzanine de **Eurazeo Private Debt**.\\n   - **Cession des Participations** : Les actionnaires existants, **Equistone Partners Europe** et **Sagard**, ont cédé leurs participations dans ce cadre.\\n\\n2. **Stratégie de Build-up et Acquisitions** :\\n   - **Acquisition d'Evolutec Ingénierie** : En 2019, Vulcain Engineering a racheté Evolutec Ingénierie, renforçant ainsi son expertise dans les domaines de l'énergie et de la chimie.\\n   - **Acquisition d'Apsalys** : Plus récemment, Vulcain a acquis **Apsalys**, un éditeur de logiciels de gestion de la qualité basés sur le cloud pour le secteur des sciences de la vie. Cette acquisition permet à Vulcain de diversifier son offre et de prioriser son développement dans ce secteur en pleine croissance.\\n   - **Acquisition de Pagoline Groupe** : Vulcain Engineering a également acquis **Pagoline Groupe**, spécialisé dans l'ingénierie appliquée aux réseaux et infrastructures, notamment dans l'énergie, le transport ferroviaire et les télécommunications. Cette acquisition est un élément clé pour la croissance à long terme de l'entreprise.\\n\\n3. **Expansion et Renforcement de l'Offre de Services** :\\n   - **Expansion Internationale** : La nouvelle structure capitalistique vise à soutenir l'expansion internationale de Vulcain Engineering, lui permettant de renforcer sa présence sur de nouveaux marchés.\\n   - **Diversification des Services** : En intégrant des entreprises comme Apsalys et Pagoline, Vulcain renforce son offre de services, couvrant désormais davantage de secteurs tels que les sciences de la vie, les infrastructures de transport et les télécommunications.\\n\\n4. **Soutien de Partenaires Stratégiques** :\\n   - **Présence dans les Portefeuilles d'Investisseurs** : Vulcain est également présente dans les portefeuilles de **Nixen Partners**, **Trocadero Capital Partners** et **Initiative & Finance**, ce qui témoigne de la confiance continue des investisseurs dans la stratégie de croissance de l'entreprise.\\n\\nCes développements témoignent de la dynamique de croissance de Vulcain Engineering, qui s'appuie sur des opérations de financement structurées et une stratégie d'acquisitions ciblées pour renforcer sa position sur le marché et diversifier ses domaines d'expertise.\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi Query: Different Perspectives\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate ten \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspectives \n",
    "    | ChatOpenAI(model= 'o1-mini') \n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    " \n",
    "# Retrieve\n",
    "question = \"Quelles nouveautées pour Vulcain ingénierie ?\"\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\":question})\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Tu es un assistant chatbot qui travaille dans un cabinet de finance d'entreprise. Ton rôle est de donner les informations les plus pertinentes possibles en te basant sur les sources que tu as. Voici le contexte pour t'aider:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOpenAI(model='o1-mini')\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG FUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Fiche Société : Imagerie Cardinet**\\n\\n---\\n\\n**Nom de la Société :**  \\nImagerie Cardinet\\n\\n**Localisation :**  \\nParis, France\\n\\n**Site Web :**  \\n[www.imagerie-cardinet.fr](http://www.imagerie-cardinet.fr)\\n\\n**Secteur d'Activité :**  \\nSanté – Imagerie Médicale\\n\\n**Domaines de Compétence :**  \\n- Intégration de logiciels de radiologie  \\n- Imagerie médicale  \\n- Imagerie dentaire  \\n- Image numérique  \\n- Traitement numérique d'images  \\n- Analyse médicale  \\n- Traitement d'image numérique\\n\\n**Description :**  \\nImagerie Cardinet est une entreprise spécialisée dans les services d'imagerie médicale destinés aux prestataires de soins de santé et aux patients. Elle offre une gamme complète de solutions numériques et logicielles pour améliorer la qualité et l'efficacité des diagnostics médicaux.\\n\\n**Principales Activités :**  \\n- Développement et intégration de logiciels de radiologie  \\n- Fourniture de services d'imagerie médicale et dentaire  \\n- Traitement et analyse numérique des images médicales  \\n- Support et maintenance des systèmes d'imagerie pour les établissements de santé\\n\\n**Dernières Actualités :**  \\n- **Collaboration avec Radiologie Paris Ouest (2023) :**  \\n  Imagerie Cardinet a établi un partenariat avec Radiologie Paris Ouest, un groupe de centres de radiologie générale et spécialisée. Cette collaboration, soutenue par Andera Acto depuis 2023, vise à renforcer le modèle entrepreneurial des deux entités et à accélérer le développement de leurs activités dans la région parisienne.\\n\\n- **Transaction avec Azulis Capital (Depuis 2019) :**  \\n  Dans le cadre de cette transaction, Azulis Capital a cédé sa participation minoritaire détenue depuis 2019, permettant à Imagerie Cardinet de poursuivre son plan de croissance et d'innovation dans le domaine de l'imagerie médicale.\\n\\n**Stratégie de Développement :**  \\nImagerie Cardinet ambitionne de renforcer sa position sur le marché de l'imagerie médicale en France en diversifiant son offre et en élargissant son portefeuille clients. La société mise également sur des partenariats stratégiques et des collaborations pour accélérer son expansion et intégrer de nouvelles technologies dans ses services.\\n\\n**Informations Financières :**  \\nLes informations financières spécifiques telles que le chiffre d'affaires ne sont pas fournies dans le contexte disponible.\\n\\n**Contacts Clés :**  \\nLes informations concernant les dirigeants ou les contacts spécifiques ne sont pas disponibles dans le contexte fourni.\\n\\n---\\n\\n**Résumé :**  \\nImagerie Cardinet se positionne comme un acteur clé dans le secteur de l'imagerie médicale en France, offrant des solutions innovantes et intégrées aux professionnels de santé et aux patients. Grâce à des partenariats stratégiques et une expertise technologique, l'entreprise vise à améliorer la qualité des diagnostics médicaux et à soutenir la croissance continue de ses activités.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAG-Fusion: Related\n",
    "template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (4 queries):\"\"\"\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "question = \"Fais moi une fiche société sur Cardinet ?\"\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_rag_fusion \n",
    "    | ChatOpenAI(model='o1-mini')\n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\" Reciprocal_rank_fusion that takes multiple lists of ranked documents \n",
    "        and an optional parameter k used in the RRF formula \"\"\"\n",
    "    \n",
    "    # Initialize a dictionary to hold fused scores for each unique document\n",
    "    fused_scores = {}\n",
    "\n",
    "    # Iterate through each list of ranked documents\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)\n",
    "            doc_str = dumps(doc)\n",
    "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # Retrieve the current score of the document, if any\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # Update the score of the document using the RRF formula: 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
    "    return reranked_results\n",
    "\n",
    "retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "docs = retrieval_chain_rag_fusion.invoke({\"question\": question})\n",
    "llm = ChatOpenAI(model='o1-mini')\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain_rag_fusion, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_fusion_actualites(question: str) -> str:\n",
    "    # Configurer les clés API\n",
    "    # Charger les clés API depuis les variables d'environnement\n",
    "    os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "    os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "    os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "    os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "    os.environ['LANGCHAIN_API_KEY'] = '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'\n",
    "\n",
    "    os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "    faiss_index_path = \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_MnA\\\\Data\\\\FAISS_index_actualites\"\n",
    "    embedding = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.load_local(\n",
    "            faiss_index_path, \n",
    "            embeddings=embedding, \n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "\n",
    "    # Créer un système de récupération\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"mmr\",  # Utiliser Maximal Marginal Relevance\n",
    "        search_kwargs={\n",
    "            \"k\": 10,  # Récupérer plus de documents\n",
    "            \"score_threshold\": 0.01  # Réduire le seuil de score pour inclure plus de résultats\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Génération des requêtes\n",
    "    query_generation_template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "    Generate multiple search queries related to: {question} \\n\n",
    "    Output (4 queries):\"\"\"\n",
    "    prompt_rag_fusion = ChatPromptTemplate.from_template(query_generation_template)\n",
    "\n",
    "    generate_queries = (\n",
    "        prompt_rag_fusion\n",
    "        | ChatOpenAI(model='o1-mini')\n",
    "        | StrOutputParser()\n",
    "        | (lambda x: x.split(\"\\n\"))  # Liste des requêtes\n",
    "    )\n",
    "\n",
    "    # Étape 1 : Générer les requêtes\n",
    "    queries = generate_queries.invoke({\"question\": question})\n",
    "    print(f\"Requêtes générées : {queries}\")\n",
    "\n",
    "    # Étape 2 : Récupération des documents\n",
    "    results = [retriever.invoke(q) for q in queries]\n",
    "    print(f\"Documents récupérés : {results}\")\n",
    "\n",
    "    # Étape 3 : Fusion Reciprocal Rank Fusion\n",
    "    fused_scores = {}\n",
    "    for docs in results:\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convertir le Document en dict avant la sérialisation\n",
    "            doc_dict = {\n",
    "                \"page_content\": doc.page_content,\n",
    "                \"metadata\": doc.metadata\n",
    "            }\n",
    "            doc_str = dumps(doc_dict)\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            fused_scores[doc_str] += 1 / (rank + 60)\n",
    "\n",
    "    reranked_docs = [\n",
    "        (Document(page_content=d[\"page_content\"], metadata=d[\"metadata\"]), score)\n",
    "        for d_str, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        for d in [loads(d_str)]\n",
    "        ]    \n",
    "    \n",
    "    print(f\"Documents fusionnés : {len(reranked_docs)} documents rerankés.\")\n",
    "\n",
    "    # Préparer le contexte pour le modèle LLM\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc, _ in reranked_docs])\n",
    "\n",
    "    # Étape 4 : Répondre à la question\n",
    "    answer_template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    answer_prompt = ChatPromptTemplate.from_template(answer_template)\n",
    "    llm = ChatOpenAI(model='o1-mini')\n",
    "\n",
    "    # Génération de la réponse\n",
    "    final_input = {\"context\": context, \"question\": question}\n",
    "    answer = (\n",
    "        answer_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    ).invoke(final_input)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_fusion_fonds(question: str) -> str:\n",
    "    # Configurer les clés API\n",
    "    # Charger les clés API depuis les variables d'environnement\n",
    "    os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "    os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "    os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "    os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "    os.environ['LANGCHAIN_API_KEY'] = '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'\n",
    "\n",
    "    os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "    faiss_index_path = \"C:\\\\Users\\\\namar\\\\Documents\\\\poc_RAG\\\\Projet_test\\\\RAG_MnA\\\\Data\\\\FAISS_index_fonds\"\n",
    "    embedding = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.load_local(\n",
    "            faiss_index_path, \n",
    "            embeddings=embedding, \n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "\n",
    "    # Créer un système de récupération\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"mmr\",  # Utiliser Maximal Marginal Relevance\n",
    "        search_kwargs={\n",
    "            \"k\": 10,  # Récupérer plus de documents\n",
    "            \"score_threshold\": 0.01  # Réduire le seuil de score pour inclure plus de résultats\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Génération des requêtes\n",
    "    query_generation_template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "    Generate multiple search queries related to: {question} \\n\n",
    "    Output (4 queries):\"\"\"\n",
    "    prompt_rag_fusion = ChatPromptTemplate.from_template(query_generation_template)\n",
    "\n",
    "    generate_queries = (\n",
    "        prompt_rag_fusion\n",
    "        | ChatOpenAI(model='o1-mini')\n",
    "        | StrOutputParser()\n",
    "        | (lambda x: x.split(\"\\n\"))  # Liste des requêtes\n",
    "    )\n",
    "\n",
    "    # Étape 1 : Générer les requêtes\n",
    "    queries = generate_queries.invoke({\"question\": question})\n",
    "    print(f\"Requêtes générées : {queries}\")\n",
    "\n",
    "    # Étape 2 : Récupération des documents\n",
    "    results = [retriever.invoke(q) for q in queries]\n",
    "    print(f\"Documents récupérés : {results}\")\n",
    "\n",
    "    # Étape 3 : Fusion Reciprocal Rank Fusion\n",
    "    fused_scores = {}\n",
    "    for docs in results:\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convertir le Document en dict avant la sérialisation\n",
    "            doc_dict = {\n",
    "                \"page_content\": doc.page_content,\n",
    "                \"metadata\": doc.metadata\n",
    "            }\n",
    "            doc_str = dumps(doc_dict)\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            fused_scores[doc_str] += 1 / (rank + 60)\n",
    "\n",
    "    reranked_docs = [\n",
    "        (Document(page_content=d[\"page_content\"], metadata=d[\"metadata\"]), score)\n",
    "        for d_str, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        for d in [loads(d_str)]\n",
    "        ]    \n",
    "    \n",
    "    print(f\"Documents fusionnés : {len(reranked_docs)} documents rerankés.\")\n",
    "\n",
    "    # Préparer le contexte pour le modèle LLM\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc, _ in reranked_docs])\n",
    "\n",
    "    # Étape 4 : Répondre à la question\n",
    "    answer_template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    answer_prompt = ChatPromptTemplate.from_template(answer_template)\n",
    "    llm = ChatOpenAI(model='o1-mini')\n",
    "\n",
    "    # Génération de la réponse\n",
    "    final_input = {\"context\": context, \"question\": question}\n",
    "    answer = (\n",
    "        answer_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    ).invoke(final_input)\n",
    "\n",
    "    return answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
